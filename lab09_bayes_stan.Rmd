---
title: "Stat 343 Bayes Practice with Stan"
output:
  pdf_document:
    keep_tex: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(readr)
library(ggplot2)
```

\newcommand{\simiid}{{\mathrel {\mathop {\sim}\limits _{}^{\rm iid}}\,}}

# Earthquakes

This example is taken from Chihara and Hesterberg.  Here's a quote from them:

> "The Weibull distribution has been used to model the time between successive earthquakes (Hasumi et al (2009); Tiampo et al. (2008)). The data set `quakes` contains the time between earthquakes (in days) for all earthquakes of magnitude 6 or greater from 1970 through 2009 (from http://earthquake.usgs.gov/earthquakes/eqarchives/)."

The R code below reads the data in and makes an initial plot:

```{r, message = FALSE}
library(tidyverse)
library(rstan)
rstan_options(auto_write = TRUE)

quakes <- read_csv("http://www.evanlray.com/data/chihara_hesterberg/Quakes.csv")

ggplot(data = quakes, mapping = aes(x = TimeDiff)) +
  geom_histogram(mapping = aes(y = ..density..))
```

We have previously estimated the parameters of a Weibull model for wind speeds via Maximum Likelihood Estimation; recall that we had to do this via numerical optimization.  Let's fit a Weibull distribution to the earthquake timing data, but using a Bayesian approach and MCMC this time.  

So, we'll use the model

$X_i \simiid \text{Weibull}(k, \lambda)$,

where $X_i$ is the $i$th observed time between consecutive earthquakes.

Recall that the Weibull distribution has two parameters, the shape parameter $k > 0$ and the scale parameter $\lambda > 0$.  If $X \sim \text{Weibull}(k, \lambda)$, then it has pdf
$$f(x | k, \lambda) = \frac{k x^{k - 1}}{\lambda^k}e^{-(x/\lambda)^k}$$

In R, the density function can be evaluated with the `dweibull` function, which has the following arguments:

* `x`: vector of values at which to evaluate the pdf.
* `shape`, `scale`: shape and scale parameters, the latter defaulting to 1.
* `log`: logical; if TRUE, returns the log of the pdf.

#### 1. Set up model definition in stan

I have set up a skeleton of the stan file, included in this repository.  Edit that file now to add necessary declarations and model statements for this model to the data, parameters, and model blocks.  The stan function to use for the Weibull distribution is called `weibull`.

See the included `earthquakes_model.stan` file for the Stan code.

I asked you to use prior of $k \sim \text{Exponential}(0.01)$ and $\lambda \sim \text{Exponential}(0.01)$.  Here is a plot of what this prior looks like.

```{r}
ggplot(data = data.frame(k = c(0, 100)), mapping = aes(x = k)) +
  stat_function(fun = dexp, args = list(rate = 0.01))
```

#### 2. Perform estimation

You will need to load the rstan package, set up a list with the data for the stan model, and call `stan` to compile the model and perform sampling.

```{r}
library(rstan)

fit <- stan("earthquakes_model.stan",
  data = list(n = nrow(quakes), x = quakes$TimeDiff),
  iter = 1000,
  chains = 4)
```

#### 3. Plot results

Make some exploratory plots of the results.  It would be nice to have:

 * a scatterplot of the posterior samples, showing both parameters for each sample from the posterior
 * histograms or density plots summarizing the marginal posterior distribution for each model parameter.

```{r}
samples <- as.data.frame(fit)
head(samples)
```

#### 4. Find posterior means and credible intervals

Obtain approximate posterior means and 95% posterior credible intervals for each model parameter.

Posterior mean and 95% CI for k:

```{r}
samples %>%
  summarize(
    post_mean_k = mean(k),
    post_95CI_k_lower = quantile(k, probs = 0.025),
    post_95CI_k_upper = quantile(k, probs = 0.975)
  )
```

Interpretation: based on the observed data, a point estimate of $k$ is the posterior mean of 0.916; there is a 95% probability that $k$ is between about 0.868 and 0.965.

I did not ask you to make this plot, but it's nice to just confirm how these relate to the samples from the posterior:

```{r}
ggplot(data = samples, mapping = aes(x = k)) +
  geom_histogram() +
  geom_vline(xintercept = 0.916, color = "orange") +
  geom_vline(xintercept = 0.868, color = "cornflowerblue") +
  geom_vline(xintercept = 0.965, color = "cornflowerblue") +
  theme_bw()
```


Posterior mean and 95% CI for $\lambda$

```{r}
samples %>%
  summarize(
    post_mean_lambda = mean(lambda),
    post_95CI_lambda_lower = quantile(lambda, probs = 0.025),
    post_95CI_lambda_upper = quantile(lambda, probs = 0.975)
  )
```

Interpretation: based on the observed data, a point estimate of $\lambda$ is the posterior mean of 17.363; there is a 95% probability that $\lambda$ is between about 16.067 and 18.761.

I did not ask you to make this plot, but it's nice to just confirm how these relate to the samples from the posterior:

```{r}
ggplot(data = samples, mapping = aes(x = lambda)) +
  geom_histogram() +
  geom_vline(xintercept = 17.363, color = "orange") +
  geom_vline(xintercept = 16.067, color = "cornflowerblue") +
  geom_vline(xintercept = 18.761, color = "cornflowerblue") +
  theme_bw()
```

#### 5. What is your effective sample size for each parameter?

```{r}
nrow(samples)
fit
```

We had four Markov chains; each generated 1000 samples, but we discarded the first 500 samples from each as burn-in.  Thus, we have a total of 2000 samples.

However, because of dependence in consecutive samples generated from a given Markov chain, we have an *effective* samples size less than 2000.  Our 2000 dependent samples give us about as much information about what the posterior looks like as roughly 1297 independent samples for $k$, and about 1382 independent samples for $\lambda$.

Here's some code that I'm including to explore this more, but it's not a priority for you to dive into this in this class.

```{r}
samples_array <- as.array(fit)
samples_by_chain <- bind_rows(
  samples_array[, 1, 1:2] %>%
    as.data.frame() %>%
    mutate(
      k_previous = lag(k, 1),
      iteration = row_number(),
      chain = 1
    ),
  samples_array[, 2, 1:2] %>%
    as.data.frame() %>%
    mutate(
      k_previous = lag(k, 1),
      iteration = row_number(),
      chain = 2
    ),
  samples_array[, 3, 1:2] %>%
    as.data.frame() %>%
    mutate(
      k_previous = lag(k, 1),
      iteration = row_number(),
      chain = 3
    ),
  samples_array[, 4, 1:2] %>%
    as.data.frame() %>%
    mutate(
      k_previous = lag(k, 1),
      iteration = row_number(),
      chain = 4
    )
)

ggplot(data = samples_by_chain, mapping = aes(x = iteration, y = k)) +
  geom_line() +
  facet_wrap( ~ chain) +
  theme_bw()

ggplot(data = samples_by_chain, mapping = aes(x = k_previous, y = k)) +
  geom_point() +
  geom_smooth(method = "lm")
```

The lack of independence between consecutive samples is indicated by the slight trend in the scatter plot above.   In this plot, each point has coordinates (sampled value of $k$ at iteration $i-1$, sampled value of $k$ at iteration $i$).  The slight trend indicates correlation between these sampled values; knowing the sampled value of k at iteration $i-1$ tells you a little bit about the sampled value of k at iteration $i$.

#### 6. Add three new layers to the data plot below: 1) a Weibull density using the posterior mean parameter values; 2) a Weibull density using the parameter values at the lower endpoints of the 95% credible intervals; and 3) a Weibull density using the parameter values at the upper endpoints of the 95% credible intervals.

```{r}
ggplot(data = quakes, mapping = aes(x = TimeDiff)) +
  geom_histogram(mapping = aes(y = ..density..), boundary = 0, binwidth = 5) +
  stat_function(fun = dweibull, args = list(shape = 0.916, scale = 17.363), color = "orange") +
  stat_function(fun = dweibull, args = list(shape = 0.868, scale = 16.067), color = "cornflowerblue") +
  stat_function(fun = dweibull, args = list(shape = 0.965, scale = 18.761), color = "purple") +
  theme_bw()
```
